Aqui est√° um modelo para o seu README, explicando as partes essenciais do c√≥digo:

---

# **Simple_bot: Converse com seu PDF** üìÑ

Um chatbot RAG (Retrieval-Augmented Generation) constru√≠do com **Streamlit**, **LangChain** e **Hugging Face**, permitindo que os usu√°rios carreguem documentos PDF e fa√ßam perguntas com base no conte√∫do.

---

## **üöÄ Funcionalidades**
- **Carregamento de PDFs:** Os usu√°rios podem carregar arquivos PDF diretamente.
- **Processamento de documentos:** Os PDFs s√£o divididos em chunks para vetoriza√ß√£o eficiente.
- **Busca de informa√ß√µes:** Respostas s√£o geradas com base no conte√∫do do documento.
- **Interface amig√°vel:** Constru√≠da em **Streamlit** com suporte a chat interativo.

---

## **üõ† Tecnologias Utilizadas**
- **Python**
- **Streamlit** para a interface web.
- **LangChain** para RAG e processamento de textos.
- **Hugging Face** para embeddings e gera√ß√£o de respostas.
- **ChromaDB** como banco de vetores.

---

## **üìÇ Estrutura do C√≥digo**

### **1. Classe `RAGChatbot`**
A classe principal do projeto, que gerencia o pipeline completo:
- **`load_document(pdf_file):`**  
  Carrega e processa arquivos PDF usando `PyPDFLoader`.

- **`process_document(documents):`**  
  Divide o texto em chunks e cria embeddings com `HuggingFaceEmbeddings`. Os vetores s√£o armazenados no `ChromaDB`.

- **`create_conversation_chain():`**  
  Cria a cadeia de conversa√ß√£o usando o modelo LLM hospedado na Hugging Face e um prompt personalizado.

- **`chat(question):`**  
  Realiza perguntas ao modelo e retorna respostas baseadas no conte√∫do.

---

### **2. `main()`**
O ponto de entrada do aplicativo:
- **Sidebar:** Carregamento de PDFs.
- **Chat interativo:** Entrada do usu√°rio via `st.chat_input` para fazer perguntas.
- **Mensagens:** Exibe mensagens enviadas pelo usu√°rio e respostas do chatbot.

---

### **3. Prompt Customizado**
O prompt usado para guiar as respostas do modelo:
```text
Baseie-se estritamente no contexto fornecido para responder a pergunta.
Se a resposta n√£o estiver no contexto, indique que n√£o possui informa√ß√µes suficientes.

INSTRU√á√ïES IMPORTANTES:
- Forne√ßa uma resposta COMPLETA e DETALHADA.
- N√ÉO INTERROMPA a resposta no meio.
- Se necess√°rio, use par√°grafos adicionais para explicar completamente.
- Garanta que a explica√ß√£o seja clara e abrangente.
```

---

## **‚öôÔ∏è Como Usar**
1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/SEU_USUARIO/Simple_bot.git
   cd Simple_bot
   ```

2. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt
   ```

3. Configure o arquivo `.env` com seu token da Hugging Face:
   ```env
   HF_TOKEN=seu_token
   ```

4. Inicie o aplicativo:
   ```bash
   streamlit run app.py
   ```

5. Carregue um PDF e fa√ßa perguntas diretamente no chat.

---

## **üîë Pontos Essenciais do C√≥digo**
- **Carregamento seguro de PDFs:** Arquivos s√£o processados usando `tempfile` para evitar problemas de seguran√ßa.
- **RAG Pipeline:** Combina√ß√£o de vetoriza√ß√£o (`HuggingFaceEmbeddings` e `ChromaDB`) com modelos LLM para respostas precisas.
- **Interface Streamlit:** Oferece uma experi√™ncia fluida e interativa.

---

## **üìú Licen√ßa**
Este projeto est√° licenciado sob a [MIT License](LICENSE).

---

Sinta-se √† vontade para modificar ou expandir este modelo conforme necess√°rio!
### **Desenvolvido por**  
[TheuxSR](https://github.com/TheuxSR) üíª
